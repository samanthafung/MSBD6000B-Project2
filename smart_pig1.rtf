{\rtf1\ansi\ansicpg1252\cocoartf1561\cocoasubrtf100
{\fonttbl\f0\fnil\fcharset0 Menlo-Regular;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;\red255\green255\blue255;}
{\*\expandedcolortbl;;\csgray\c0;\csgray\c100000;}
\paperw11900\paperh16840\margl1440\margr1440\vieww10800\viewh8400\viewkind0
\pard\tx560\tx1120\tx1680\tx2240\tx2800\tx3360\tx3920\tx4480\tx5040\tx5600\tx6160\tx6720\pardirnatural\partightenfactor0

\f0\fs22 \cf2 \cb3 \CocoaLigature0 (tensorflow_p36) [ec2-user@ip-172-31-12-250 project2]$ sudo python3 smart_pig1.py \
Using TensorFlow backend.\
Found 3119 images belonging to 5 classes.\
Found 550 images belonging to 5 classes.\
_________________________________________________________________\
Layer (type)                 Output Shape              Param #   \
=================================================================\
conv2d_1 (Conv2D)            (None, 62, 62, 64)        1792      \
_________________________________________________________________\
activation_1 (Activation)    (None, 62, 62, 64)        0         \
_________________________________________________________________\
max_pooling2d_1 (MaxPooling2 (None, 31, 31, 64)        0         \
_________________________________________________________________\
conv2d_2 (Conv2D)            (None, 29, 29, 32)        18464     \
_________________________________________________________________\
activation_2 (Activation)    (None, 29, 29, 32)        0         \
_________________________________________________________________\
max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \
_________________________________________________________________\
dropout_1 (Dropout)          (None, 14, 14, 32)        0         \
_________________________________________________________________\
conv2d_3 (Conv2D)            (None, 12, 12, 64)        18496     \
_________________________________________________________________\
activation_3 (Activation)    (None, 12, 12, 64)        0         \
_________________________________________________________________\
max_pooling2d_3 (MaxPooling2 (None, 6, 6, 64)          0         \
_________________________________________________________________\
flatten_1 (Flatten)          (None, 2304)              0         \
_________________________________________________________________\
dense_1 (Dense)              (None, 128)               295040    \
_________________________________________________________________\
activation_4 (Activation)    (None, 128)               0         \
_________________________________________________________________\
dropout_2 (Dropout)          (None, 128)               0         \
_________________________________________________________________\
dense_2 (Dense)              (None, 5)                 645       \
_________________________________________________________________\
activation_5 (Activation)    (None, 5)                 0         \
=================================================================\
Total params: 334,437\
Trainable params: 334,437\
Non-trainable params: 0\
_________________________________________________________________\
None\
Epoch 1/50\
2017-11-22 12:22:06.667635: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\
98/97 [==============================] - 14s 143ms/step - loss: 1.4185 - acc: 0.3698 - val_loss: 1.1951 - val_acc: 0.5364\
Epoch 2/50\
98/97 [==============================] - 13s 129ms/step - loss: 1.2112 - acc: 0.4874 - val_loss: 1.1579 - val_acc: 0.4873\
Epoch 3/50\
98/97 [==============================] - 13s 129ms/step - loss: 1.1387 - acc: 0.5401 - val_loss: 1.0764 - val_acc: 0.5600\
Epoch 4/50\
98/97 [==============================] - 13s 130ms/step - loss: 1.0737 - acc: 0.5750 - val_loss: 1.0044 - val_acc: 0.6255\
Epoch 5/50\
98/97 [==============================] - 13s 131ms/step - loss: 1.0389 - acc: 0.5826 - val_loss: 1.0156 - val_acc: 0.6145\
Epoch 6/50\
98/97 [==============================] - 13s 130ms/step - loss: 1.0070 - acc: 0.6007 - val_loss: 0.9361 - val_acc: 0.6564\
Epoch 7/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.9623 - acc: 0.6242 - val_loss: 0.9083 - val_acc: 0.6491\
Epoch 8/50\
98/97 [==============================] - 13s 128ms/step - loss: 0.9380 - acc: 0.6189 - val_loss: 0.8870 - val_acc: 0.6673\
Epoch 9/50\
98/97 [==============================] - 13s 129ms/step - loss: 0.9090 - acc: 0.6455 - val_loss: 0.8596 - val_acc: 0.6691\
Epoch 10/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.8910 - acc: 0.6497 - val_loss: 0.8544 - val_acc: 0.6636\
Epoch 11/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.8628 - acc: 0.6671 - val_loss: 0.8510 - val_acc: 0.6673\
Epoch 12/50\
98/97 [==============================] - 13s 129ms/step - loss: 0.8539 - acc: 0.6707 - val_loss: 0.7838 - val_acc: 0.7127\
Epoch 13/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.8409 - acc: 0.6801 - val_loss: 0.7738 - val_acc: 0.7200\
Epoch 14/50\
98/97 [==============================] - 13s 129ms/step - loss: 0.8078 - acc: 0.6854 - val_loss: 0.7575 - val_acc: 0.7091\
Epoch 15/50\
98/97 [==============================] - 13s 128ms/step - loss: 0.8053 - acc: 0.6883 - val_loss: 0.7569 - val_acc: 0.7182\
Epoch 16/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.7773 - acc: 0.7004 - val_loss: 0.7144 - val_acc: 0.7309\
Epoch 17/50\
98/97 [==============================] - 13s 128ms/step - loss: 0.7750 - acc: 0.7033 - val_loss: 0.7137 - val_acc: 0.7182\
Epoch 18/50\
98/97 [==============================] - 13s 131ms/step - loss: 0.7517 - acc: 0.7090 - val_loss: 0.7138 - val_acc: 0.7127\
Epoch 19/50\
98/97 [==============================] - 13s 129ms/step - loss: 0.7412 - acc: 0.7158 - val_loss: 0.6836 - val_acc: 0.7345\
Epoch 20/50\
98/97 [==============================] - 13s 131ms/step - loss: 0.7381 - acc: 0.7245 - val_loss: 0.6968 - val_acc: 0.7255\
Epoch 21/50\
98/97 [==============================] - 13s 129ms/step - loss: 0.7157 - acc: 0.7311 - val_loss: 0.6677 - val_acc: 0.7509\
Epoch 22/50\
98/97 [==============================] - 13s 129ms/step - loss: 0.7219 - acc: 0.7207 - val_loss: 0.6653 - val_acc: 0.7491\
Epoch 23/50\
98/97 [==============================] - 13s 129ms/step - loss: 0.6985 - acc: 0.7344 - val_loss: 0.6497 - val_acc: 0.7545\
Epoch 24/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.6886 - acc: 0.7321 - val_loss: 0.6043 - val_acc: 0.7745\
Epoch 25/50\
98/97 [==============================] - 13s 129ms/step - loss: 0.6731 - acc: 0.7395 - val_loss: 0.6641 - val_acc: 0.7400\
Epoch 26/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.6810 - acc: 0.7401 - val_loss: 0.6722 - val_acc: 0.7382\
Epoch 27/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.6564 - acc: 0.7448 - val_loss: 0.6394 - val_acc: 0.7473\
Epoch 28/50\
98/97 [==============================] - 13s 128ms/step - loss: 0.6528 - acc: 0.7501 - val_loss: 0.6447 - val_acc: 0.7473\
Epoch 29/50\
98/97 [==============================] - 13s 128ms/step - loss: 0.6503 - acc: 0.7514 - val_loss: 0.6306 - val_acc: 0.7582\
Epoch 30/50\
98/97 [==============================] - 13s 129ms/step - loss: 0.6416 - acc: 0.7615 - val_loss: 0.5874 - val_acc: 0.7818\
Epoch 31/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.6295 - acc: 0.7586 - val_loss: 0.5886 - val_acc: 0.7582\
Epoch 32/50\
98/97 [==============================] - 13s 128ms/step - loss: 0.6211 - acc: 0.7673 - val_loss: 0.6210 - val_acc: 0.7418\
Epoch 33/50\
98/97 [==============================] - 13s 131ms/step - loss: 0.6319 - acc: 0.7668 - val_loss: 0.5501 - val_acc: 0.7945\
Epoch 34/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.6070 - acc: 0.7736 - val_loss: 0.5296 - val_acc: 0.8055\
Epoch 35/50\
98/97 [==============================] - 13s 129ms/step - loss: 0.6120 - acc: 0.7681 - val_loss: 0.5798 - val_acc: 0.7600\
Epoch 36/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.5925 - acc: 0.7650 - val_loss: 0.5178 - val_acc: 0.8055\
Epoch 37/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.5943 - acc: 0.7687 - val_loss: 0.5096 - val_acc: 0.7927\
Epoch 38/50\
98/97 [==============================] - 13s 129ms/step - loss: 0.5927 - acc: 0.7705 - val_loss: 0.5234 - val_acc: 0.7945\
Epoch 39/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.5773 - acc: 0.7855 - val_loss: 0.4898 - val_acc: 0.8218\
Epoch 40/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.5686 - acc: 0.7755 - val_loss: 0.4829 - val_acc: 0.8364\
Epoch 41/50\
98/97 [==============================] - 13s 131ms/step - loss: 0.5776 - acc: 0.7811 - val_loss: 0.5413 - val_acc: 0.7964\
Epoch 42/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.5666 - acc: 0.7752 - val_loss: 0.4967 - val_acc: 0.8182\
Epoch 43/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.5526 - acc: 0.7889 - val_loss: 0.4656 - val_acc: 0.8309\
Epoch 44/50\
98/97 [==============================] - 13s 128ms/step - loss: 0.5595 - acc: 0.7937 - val_loss: 0.4991 - val_acc: 0.8091\
Epoch 45/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.5575 - acc: 0.7955 - val_loss: 0.4546 - val_acc: 0.8327\
Epoch 46/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.5422 - acc: 0.8053 - val_loss: 0.4475 - val_acc: 0.8418\
Epoch 47/50\
98/97 [==============================] - 13s 130ms/step - loss: 0.5327 - acc: 0.7940 - val_loss: 0.4544 - val_acc: 0.8364\
Epoch 48/50\
98/97 [==============================] - 13s 131ms/step - loss: 0.5449 - acc: 0.7961 - val_loss: 0.4603 - val_acc: 0.8236\
Epoch 49/50\
98/97 [==============================] - 13s 129ms/step - loss: 0.5237 - acc: 0.8027 - val_loss: 0.4245 - val_acc: 0.8418\
Epoch 50/50\
98/97 [==============================] - 13s 128ms/step - loss: 0.5217 - acc: 0.8049 - val_loss: 0.4520 - val_acc: 0.8345\
\
acc: 83.45%\
}